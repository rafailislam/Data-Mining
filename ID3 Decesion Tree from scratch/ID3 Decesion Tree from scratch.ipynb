{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F2FElhuKCYgj"
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Assignmnet: HW2\n",
    "Course : CSC 635\n",
    "Program: hw2.ipynb\n",
    "Author: Rafail Islam\n",
    "\"\"\"\n",
    "#---------------------------------Imports--------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "#------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M3ureV4nDlMJ"
   },
   "outputs": [],
   "source": [
    "#---------------------------------Variables------------------------------------\n",
    "#only dataset for problem 01 \n",
    "training_data = [\n",
    "({'level':'Senior', 'lang':'Java', 'tweets':'no', 'phd':'no'}, False),\n",
    "({'level':'Senior', 'lang':'Java', 'tweets':'no', 'phd':'yes'}, False),\n",
    "({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'no'}, True),\n",
    "({'level':'Junior', 'lang':'Python', 'tweets':'no', 'phd':'no'}, True),\n",
    "({'level':'Junior', 'lang':'R', 'tweets':'yes', 'phd':'no'}, True),\n",
    "({'level':'Junior', 'lang':'R', 'tweets':'yes', 'phd':'yes'}, False),\n",
    "({'level':'Mid', 'lang':'R', 'tweets':'yes', 'phd':'yes'}, True),\n",
    "({'level':'Senior', 'lang':'Python', 'tweets':'no', 'phd':'no'}, False),\n",
    "({'level':'Senior', 'lang':'R', 'tweets':'yes', 'phd':'no'}, True),\n",
    "({'level':'Junior', 'lang':'Python', 'tweets':'yes', 'phd':'no'}, True),\n",
    "({'level':'Senior', 'lang':'Python', 'tweets':'yes', 'phd':'yes'}, True),\n",
    "({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'yes'}, True),\n",
    "({'level':'Mid', 'lang':'Java', 'tweets':'yes', 'phd':'no'}, True),\n",
    "({'level':'Junior', 'lang':'Python', 'tweets':'no', 'phd':'yes'}, False)\n",
    "] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QWumtXePGCnD"
   },
   "outputs": [],
   "source": [
    "#---------------------------------Functions----------------------------\n",
    "\n",
    "# converting list into dataframe for convenience \n",
    "def load_dataset_1(training_data):\n",
    "    \"\"\" this functin load data set for problem 01. it takes trainig_data as argumnet, and returns\n",
    "    a dataframe as train_df\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    training_data : tuples\n",
    "        dataset as tuples\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    train_df : pandas dataframe\n",
    "        dataset as dataframe\n",
    "        \n",
    "    \"\"\"\n",
    "    column= ['level', 'lang', 'tweets', 'phd','class_label']\n",
    "    train_df = pd.DataFrame(columns=column)\n",
    "    \n",
    "    for d in training_data:\n",
    "        dic = d[0]\n",
    "        dic['class_label']=d[1]\n",
    "        df1=pd.DataFrame([dic])\n",
    "        train_df = train_df.append(df1,ignore_index = True)\n",
    "        \n",
    "    return train_df\n",
    "\n",
    "train_df = load_dataset_1(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "A_YY_lO9i79Q",
    "outputId": "e1e1ce02-27c7-41d4-d35d-641e23718b85"
   },
   "outputs": [],
   "source": [
    "# Find entropy of class\n",
    "def entropyD(df , label ):\n",
    "    \"\"\" This function calculates endropy of a dataset. \n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    df : dataframe\n",
    "        dataset as dataframe\n",
    "        \n",
    "    label : str\n",
    "        label of the dataset\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    entropy : float\n",
    "        entropy of the dataset \n",
    "    \"\"\"\n",
    "    entropy = 0\n",
    "    # calculate entropy\n",
    "    for classLabels in df[label].unique(): \n",
    "        prob = df[label].value_counts()[classLabels]/len(df)\n",
    "        entropy += - prob * np.log2(prob)\n",
    "     \n",
    "    #print(entropy)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "# Find entropy of an attribute\n",
    "def entropyA(df,attribute,label):\n",
    "    \"\"\" This function calculates endropy of an attributes over the class of a dataset. \n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    df : dataframe\n",
    "        dataset as dataframe\n",
    "    \n",
    "    attribute : str\n",
    "        attribute name \n",
    "        \n",
    "    label : str\n",
    "        label of the dataset\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    entropy : float\n",
    "        entropy of the given attribute over class of the data set\n",
    "    \"\"\"\n",
    "    # unique values of the given attribute\n",
    "    attributeValues = df[attribute].unique()\n",
    "    \n",
    "    # unique class of the dataset\n",
    "    classLabels = df[label].unique()\n",
    "    \n",
    "    entropyAi = 0\n",
    "    # entropyA(D) = sum ( |Dj|/|D|* entropy(Dj) )\n",
    "    for value in attributeValues:\n",
    "        entropyDj = 0\n",
    "        # entropy(Dj)\n",
    "        for cLabel in classLabels:\n",
    "            # |Dj|\n",
    "            dj = len(df[attribute][df[attribute]==value][df[label]==cLabel])\n",
    "            # |D|\n",
    "            d = len(df[attribute][df[attribute]==value])\n",
    "            prob = dj/d\n",
    "            entropyDj += -prob * np.log2(prob+ np.finfo(float).eps) #RuntimeWarning: divide by zero encountered in log\n",
    "                                                              # to avoid this, I added np.finfo(float).eps\n",
    "    \n",
    "        prob = d/len(df)\n",
    "        entropyAi +=- prob * entropyDj\n",
    "        \n",
    "    return np.abs(entropyAi)\n",
    "\n",
    "# #print(entropyD(df,'class_label'))\n",
    "# print(entropyA(train_df,'level','class_label'))\n",
    "# print(entropyA(train_df,'lang','class_label'))\n",
    "# print(entropyA(train_df,'tweets','class_label'))\n",
    "# print(entropyA(train_df,'phd','class_label'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Iw4Fzl74Hzi8",
    "outputId": "eb8c499f-d7ba-48a6-de41-b576b39a582f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'level'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def infoGain(df,attribute_list,label):\n",
    "    \"\"\" This function calculates information gain of all attributes provided.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    df : dataframe\n",
    "        dataset as dataframe\n",
    "    \n",
    "    attribute_list : list of str\n",
    "        attribute list \n",
    "        \n",
    "    label : str\n",
    "        label of the dataset\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    name of the columns with maximum information gain amoing the provided attributes\n",
    "    \"\"\"\n",
    "    # calculate entropy\n",
    "    ent_d = entropyD(df,label)\n",
    "    ent_hist=[]\n",
    "    for attr in attribute_list:\n",
    "        # calculate attributes entropy\n",
    "        ent_attr = entropyA(df,attr,label)\n",
    "        ent_hist.append(ent_d - ent_attr )\n",
    "        #print(ent_hist)\n",
    "    return df.columns[np.argmax(ent_hist)]\n",
    "\n",
    "infoGain(train_df,train_df.columns[:-1],'class_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "k8ifuojCNhKI",
    "outputId": "2159c70f-fef7-47d9-ed68-ddb1b0e182f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 'Python')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def same_class(df,label):\n",
    "    \"\"\"this function detemines the purity of a dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    df : dataframe\n",
    "        dataset \n",
    "        \n",
    "    label : str\n",
    "        label of the dataset\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    True/False : bool\n",
    "    class label : class label\n",
    "    \"\"\"\n",
    "    \n",
    "    classes, counts = np.unique(df[label],return_counts=True)\n",
    "    #print(classes,counts)\n",
    "  \n",
    "    if(len(classes) <= 1):\n",
    "        return True,classes[0]\n",
    "    else:\n",
    "        return False,classes[np.argmax(counts)]\n",
    "  \n",
    "same_class(train_df,'lang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "qxTd0b7KY_6B",
    "outputId": "f697eb17-dec1-4a26-8680-3a8eb5e58888"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_majority_class(df,label):\n",
    "    \"\"\"this function detemines mejority class of a dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    df : dataframe\n",
    "        dataset \n",
    "        \n",
    "    label : str\n",
    "        label of the dataset\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    class label : dtype of class label\n",
    "    \"\"\"\n",
    "    \n",
    "    classes, counts = np.unique(df[label],return_counts=True)\n",
    "    return classes[np.argmax(counts)]\n",
    "\n",
    "get_majority_class(train_df,'class_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GMLyDdY48C4c"
   },
   "outputs": [],
   "source": [
    "# Buid ID3 decision tree\n",
    "def ID3(df,attribute_list,label): \n",
    "    \"\"\"this function build ID3 decision tree recursively.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    df : dataframe\n",
    "        dataset \n",
    "        \n",
    "    attribute_list : list of str\n",
    "        attribute list\n",
    "        \n",
    "    label : str\n",
    "        label of the dataset\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    dt : dictionary of dictionary\n",
    "        decision tree\n",
    "    \"\"\"\n",
    "    #1 create a node\n",
    "    dt={}\n",
    "\n",
    "    # 2. If samples are all of the same class C , \n",
    "    # then return N as a leaf node labeled with class C\n",
    "    purity, class_label = same_class(df,label)\n",
    "    if purity:\n",
    "        #print(\"pure\")\n",
    "        dt = class_label\n",
    "        return dt\n",
    "\n",
    "    # 3. if attributes_list is empty, then return n as a leaf node labeled with the majority class\n",
    "    if  len(attribute_list) == 0:\n",
    "        #print(\"attr empty\")\n",
    "        dt = get_majority_class(df,label)\n",
    "        return dt\n",
    "\n",
    "    # 4. select test_attribute with most information gain\n",
    "    test_attribute = infoGain(df,attribute_list,label)\n",
    "    #print(\"best\\t\",test_attribute)\n",
    "\n",
    "    # 5. Label node N with test_attribute\n",
    "    dt={test_attribute:None}\n",
    "\n",
    "    # 6. For each known value ai of test_attribute\n",
    "    #i. grow a branch from node N for the condition test_attribute = ai\n",
    "    branch ={}\n",
    "    branch[None]= get_majority_class(df,label)\n",
    "    for next_test_attribute in df[test_attribute].unique():\n",
    "        branch[next_test_attribute] = None \n",
    "\n",
    "    #pprint.pprint(branch)\n",
    "\n",
    "    dt[test_attribute]= branch\n",
    "  \n",
    "    for value in df[test_attribute].unique():\n",
    "        \n",
    "        #print(\"value\\t\",value)\n",
    "    \n",
    "        # 6 ii. let S i be the set of samples in D for which test_attribute = ai\n",
    "        si = df[df[test_attribute] == value].reset_index(drop=True)\n",
    "        #print(si)\n",
    "    \n",
    "        # 6 iii. if S i is empty, then attach a leaf node labeled with the majority class in D\n",
    "        if len(si)==0 :\n",
    "            print(\"empty sub set\")\n",
    "            dt[test_attribute][value]= get_majority_class(df,label)\n",
    "            return dt\n",
    "        else:\n",
    "            dt[test_attribute][value] = ID3(si,si.columns[:-1],si.columns[-1])\n",
    "\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "U0eS-W10nUfK"
   },
   "outputs": [],
   "source": [
    "\n",
    "def classify(sample,dt):\n",
    "    \"\"\"this function determine the result of a decision tree\n",
    "    for a single sample\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    sample : dictionary \n",
    "        sample data to predict class \n",
    "    \n",
    "    dt : dictionary of dictionary\n",
    "        decision tree\n",
    "    Returns\n",
    "    ----------\n",
    "    decision : dtype of leaf node\n",
    "        label of the predicted class\n",
    "    \"\"\"\n",
    "    \n",
    "    #Recursively traverse the tree \n",
    "    for node in dt.keys():\n",
    "        \n",
    "        # for missing data returns majority class\n",
    "        if node not in sample.keys():\n",
    "            return dt[node][None]\n",
    "        \n",
    "        attribute = sample[node]\n",
    "        \n",
    "        # for incurrect data returns majority class\n",
    "        if attribute not in dt[node].keys():\n",
    "            return dt[node][None]\n",
    "        \n",
    "        dt = dt[node][attribute]\n",
    "        #pprint.pprint(dt)\n",
    "        decision = False\n",
    "\n",
    "        #go until we reach leaf node\n",
    "        if isinstance(dt,dict) :\n",
    "            decision = classify(sample, dt)\n",
    "        else:\n",
    "            decision = dt\n",
    "            #print(tree)\n",
    "            break;                            \n",
    "        \n",
    "    return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "Dt2Fcu1Kqu4s",
    "outputId": "d0174b8e-1faa-4d76-e9e6-4bed92f73d7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': {None: True,\n",
      "           'Junior': {'phd': {None: True, 'no': True, 'yes': False}},\n",
      "           'Mid': True,\n",
      "           'Senior': {'tweets': {None: False, 'no': False, 'yes': True}}}}\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Here we do all the steps in problem 01\n",
    "def problem1():\n",
    "    \n",
    "    # Load data\n",
    "    train_df = load_dataset_1(training_data)\n",
    "    \n",
    "    # Build decision tree\n",
    "    dt = ID3(train_df,train_df.columns[:-1],train_df.columns[-1])\n",
    "    pprint.pprint(dt)\n",
    "    \n",
    "    # sample test data\n",
    "    sample1 = {\"level\" : \"Senior\",\"lang\" : \"Java\",\"tweets\" : \"yes\",'phd' : 'no'} # true\n",
    "    sample2 = {\"level\" : \"Junior\",\"lang\" : \"Java\",\"tweets\" : \"yes\",\"phd\" : \"yes\"} # false\n",
    "    sample3 = {\"level\": \"Intern\"} # true\n",
    "    sample4 = {\"level\": \"Senior\"} # false\n",
    "    \n",
    "    # classify test data\n",
    "    print(classify(sample1, dt))\n",
    "    print(classify(sample2, dt))\n",
    "    print(classify(sample3, dt))\n",
    "    print(classify(sample4, dt))\n",
    "\n",
    "problem1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMIDxPDVNK9Y"
   },
   "source": [
    "# Problem 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset for problem 02\n",
    "def load_dataset2():\n",
    "    \"\"\" Load dataset and returns data for training and testing\n",
    "    Parameters\n",
    "    --------\n",
    "    null\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    training_data : dataframe\n",
    "        training dataset\n",
    "    \n",
    "    X_test : dataframe\n",
    "        dataset for testing\n",
    "    y_test : dataframe\n",
    "        actual class of testing dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    #https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
    "    dataset  = pd.read_csv('diabetes.csv',delimiter=',')\n",
    "    dataset.head(5)\n",
    "    \n",
    "    y = dataset['Outcome']\n",
    "    X = dataset.drop('Outcome',axis=1)\n",
    "    y= y.to_frame()\n",
    "    \n",
    "    # split dataset into test and train\n",
    "    \n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "    \n",
    "    # concatenate dataframe to make traing dataset with labels\n",
    "    train_data = pd.concat([X_train,y_train],axis=1)\n",
    "    \n",
    "    return train_data, X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "VYv-WrW9NP5n"
   },
   "outputs": [],
   "source": [
    "def classification_accuracy(dt,X_test,y_test):\n",
    "    ''' This function caculate classification accuracy\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    dt : dictionary of dictionaries\n",
    "        decision tree\n",
    "    X_test : dataframe\n",
    "        testing dataset\n",
    "    \n",
    "    Y_test : dataframe\n",
    "        actual class of testing dataset\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    Accuracy : float\n",
    "        Accuracy in percentage\n",
    "    '''\n",
    "    # Convert dataframe into dictionaries\n",
    "    samples = X_test.to_dict('records')\n",
    "    count = 0\n",
    "    # make 1D np array\n",
    "    ytest =np.squeeze(y_test.to_numpy())\n",
    "    \n",
    "    for sample, y in zip(samples,ytest):\n",
    "        # get class for single data (row)\n",
    "        y_predict = classify(sample,dt)\n",
    "        \n",
    "        if y == y_predict:\n",
    "            count += 1\n",
    "    return (count/len(X_test))*100\n",
    "\n",
    "#classification_accuracy(dt,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 57.79%\n"
     ]
    }
   ],
   "source": [
    "# Here we do all steps for problem 02\n",
    "def problem2():\n",
    "    \n",
    "    # load data\n",
    "    train_data, X_test, y_test = load_dataset2()\n",
    "    \n",
    "    # build decision tree\n",
    "    dt = ID3(train_data, attribute_list = train_data.columns[:-1], label = train_data.columns[-1])\n",
    "    \n",
    "    # print accuracy\n",
    "    print(\"Test Accuracy %.2f%%\"%(classification_accuracy(dt,X_test,y_test)))\n",
    "    \n",
    "problem2()   \n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
